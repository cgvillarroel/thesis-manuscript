[#intro]
== Introduction

This chapter provides context regarding the importance of the subject matter of the study. It provides an overview of the current state of Filipino Sign Language technologies, the problems associated with them, and the objectives this study aims to achieve to address them. It also clarifies the scope of the study.

[#context]
=== Context of the Study

Communication is a fundamental part of being a human. It is the foundation of human relationships, and humans use communication as a tool to understand, influence and build relationships with others cite:[peace20]. However, in the context of communication in the Philippines, it is not limited to the country’s 186 spoken languages cite:[borlongan23]. The Filipino Sign Language (FSL) has been recognized as the country’s national sign language since 2018 through the Filipino Sign Language (FSL) Act. This law mandates the use of FSL in schools, broadcast media, and workplaces where there are deaf individuals cite:[tinio18]. The implementation of the FSL Act aims to bridge the gap between the Filipino Deaf community and their hearing counterparts.

Despite the goal to bridge said gap, most Filipinos have yet to learn and comprehend FSL cite:[cabutaje23]. Part of this may be attributed to an unequal distribution of learning resources and a lack of teachers cite:[andrada06]. It is complex - like all languages, may it be spoken or signed. Basic signs are easy to learn through videos; continuous signs that are context-based are much harder to learn. In addition to the learning complexity, there is also a stigma against people who use sign language, commonly shown through the mockery of the signs cite:[mocha18]. There is also a limited number of institutions in the Philippines that offer sign language classes, showing its minimal accessibility to hearing and hard-of-hearing Filipinos cite:[senate18]. The implemented law has a long way to go in providing true inclusivity and accessibility to address the barriers between the deaf and hearing community.

With that said, the use of modern technology may be able to address the barriers of communication. In recent years, research on Sign Language Recognition (SLR) has been conducted to develop an artificial intelligence (AI) to aid in SLR, as detailed in <<rrl>>. Much literature has been dedicated to creating models that translate gestures into text. Many of these use sophisticated deep learning models, like recurrent neural networks, and show promising results. This is true even for FSL, where research is still somewhat premature due to the lack of extensive datasets. However, few pieces of literature branch out into other applications. For example, tools that evaluate the correctness of pronunciation exist for spoken languages, like Duolingo or Rosetta Stone. Few pieces of literature literature aim to provide tools that have similar functionality for sign languages, including FSL.

[#problem]
=== Statement of the Problem

While there exist resources for learning FSL, tools are yet to be made that provide feedback to learners. Gesture-to-text translators exist, but they provide no feedback for learners. Some models have been developed for other sign languages. However, these either do not provide feedback useful to learners or fail to take into account additional component of gestures that are important to FSL specifically (i.e., facial features).

[#questions]
=== Research Questions

This study intends to answer the following questions:

. What improvements can be made to models meant to provide feedback for sign language learning, specifically in the scope of Filipino Sign Language?
. What effects would the inclusion of facial features have on the effectiveness of the model in terms of the model's metrics, such as accuracy, precision, recall, and F1 score?

[#objectives]
=== Research Objectives

This study aims to improve upon previous research that develop feedback models for sign language learners, specifically in the scope of Filipino Sign Language (FSL). Specifically, it aims to:

. Develop a model that determines if two FSL gestures are executed similarly or not and provides feedback in the case of differences.
. Determine the effectiveness of the developed model at determining if two FSL gestures are executed similarly in terms of statistical metrics such as accuracy, precision, and recall.
. Determine the effects of including facial features in the model.

[#scope]
=== Scope and Limitations

This study does not aim to create a model that translates Filipino Sign Language gestures into text. Instead, it determines if a gesture is executed similarly to a reference gesture. The fundamental difference is that it does not attempt to extract meaning; it already knows the gesture the learner is attempting, and simply provides feedback regarding their difference. This study will be taking advantage of FSL-105 cite:[tupal23].

// Comment this if we make an app
Though this study is modeled after the work of Paudyal et al. cite:[paudyal19], it only aims to create a model. It will not attempt to develop an application that utilizes and showcases the model. As such, assessments of the model will not include qualitative feedback from users.

[#significance]
=== Significance of the Study

This study will benefit the following:

Technology Developers.::
As this study aims to develop a model to aid in FSL learning, it may be significant to developers who focus on developing technologies for deaf people. Specifically, with a model that can accurately determine if two gestures are executed similarly and accurately identify differences, FSL learning application developers may take advantage of this model to provide their users valuable detailed feedback.

Research and Academic Communities.::
Research in FSL Recognition is still being explored, and there is less literature that studies FSL than more popular sign languages like ASL. Results gathered in this study may provide insights to future researchers regarding the intricacies of FSL and the methods surrounding it and its computer-aided recognition.
